---
layout:     post
title:      BERT for Joint Intent Classification and Slot Filling
subtitle:    论文笔记
date:       2020-04-18
author:     Chestnut
header-img: img/post-bg-2015.jpg
catalog: true
tags:
    - NLU
    - joint Model
    
---

## Note
## 摘要

在许多情况下，ground truth标签并不存在，但是可以访问嘈杂的注释或来自不同域的注释。在本文中，我们提出了一个新的框架共识网络(CONNET)，它可以训练来自多个来源的注释(例如，crowd annotation人群注释，cross-domain data跨域数据)。学习每个源的个别表示，并通过上下文感知的注意模块动态聚合源特定的知识。该模型可以在多领域上反应共识(consensus)。我们在multi-source learning(多源学习)的两个实用设置中评估提出的框架：使用人群注释和无监督的跨域模型自适应进行学习。大量的实验结果表明，在两种环境下，我们的模型均比现有方法有了显着改进。 我们还证明了该方法可以适用于各种任务并可以应对不同的编码器。

## Introduction

面向问题：目标标注质量不高，但可以访问有噪音的注释或来自不同域的注释，来轻易获得不完美的注释。不同的监管来源具有不同的优势，并且对不同的情况更加精通。

论文核心：如何聚合多源不完美注释，在不知道目标域中底层真实值标记的情况下学习模型。

need to do：(1)在训练时明确地建立不同来源的独特特征的模型(2)找到可以对未见的句子进行模型泛化的最合适的来源。

annotator-invariant patterns 注释器不变模式，通过在多任务学习模式中共享部分低级模型参数来实现。

annotator-specific biases 注释器特殊偏见，为了学习偏差，我们将偏差从模型中分离出来，作为顶层标记模型参数的转换，这样它们就可以捕获每个注释器的独特强度。借助这种解耦源表示，我们进一步学习了一个注意力网络，用于通过构成表示源之间一致性的转换来动态地为每个unseen句子分配最佳源（共识）

## Multi-source Supervised Learning

提供：有监督的K个source（每个source看作不完美的注释器）

**定义**：

（k指source的序号）

第k个源数据集：<img src="C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829174455942.png" alt="image-20200829174455942" style="zoom:67%;" />，其中<img src="C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829174620407.png" alt="image-20200829174620407" style="zoom:67%;" />表示第i个句子的token序列<img src="C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829174747154.png" alt="image-20200829174747154" style="zoom:67%;" />；<img src="C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829174833020.png" alt="image-20200829174833020" style="zoom:67%;" />则为tag序列。

每个注释器的句子集定义：<img src="C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829174312834.png" alt="image-20200829174312834" style="zoom: 67%;" />

训练域即所有注释器合集定义：<img src="C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829175112124.png" alt="image-20200829175112124" style="zoom:67%;" />

**目标**：

用不完美的标注数据，训练一个模型，该模型可以对于目标语料库$T$中的任意一个句子$x$，预测其tag序列$y$。

注意： $T$ 与 $\chi$ 的分布有两种情况：要么一样(Application I)，要么明显不同 (Application II)。

![image-20200829180217436](C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829180217436.png)

#### 应用 I: 通过人群注释学习（Learning with Crowd Annotations）

不同的注释器标记相同给定数据集的子集，因此，假设输入分布在$\chi^(k)$间没有移位。

我们仅测试相同域中的句子，以使目标语料库T中的分布也相同。target corpus的边际分布与每个个体 source dataset的边际分布相同，即<img src="C:\Users\CONAN\AppData\Roaming\Typora\typora-user-images\image-20200829183308667.png" alt="image-20200829183308667" style="zoom:67%;" />

然而，由于每个source注释器的不完美性，$P_k(y|x)$从潜在的事实$P(y|x)$转移【如图左】。

在这里，multi-source learning的目标是，学习一个在相同域中的任何新句子上支持推理的模型$P_T(y|x)$。

#### 应用II: 无监督的跨域模型自适应（Unsupervised Cross-Domain Model Adaptation）

我们假设在几个源域中有可用的注释，但在看不见的目标域中没有。

我们假设不同源域$X^{(k)}$中的输入分布$P(x)$差异很大，这样的注释很难适应训练目标域模型。即只有当$x $属于$X ^{(k)}$时，各领域模型的预测分布$P_k(y|x)$才接近真实分布$P(y|x)$。

对于目标语料库句子$x$（属于$T$），这样的源模型的$P_k(y|x)$与目标域$P_T (y|x)$的基本事实有所不同，可以看作是一个不完美的注释器。

在此场景下，我们的目标仍是对$P_T(y|x)$进行联合建模，同时注意$T$与$X^{(k)}$存在显着的域偏移。



